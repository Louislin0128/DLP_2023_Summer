{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b48cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from DL_lab2_EEGclassification_model import EEGNet, DeepConvNet\n",
    "from dataloader import read_bci_data\n",
    "\n",
    "def train(train_dataloader, test_dataloader, model_name):\n",
    "    if model_name == 'EEGNet':\n",
    "        models = {\n",
    "            'EEGNet_ReLU': EEGNet(nn.ReLU()).to(device),\n",
    "            'EEGNet_LeakyReLU': EEGNet(nn.LeakyReLU()).to(device),\n",
    "            'EEGNet_ELU': EEGNet(nn.ELU()).to(device)\n",
    "        }\n",
    "        best_model_wts = {'EEGNet_ReLU':None,'EEGNet_LeakyReLU':None,'EEGNet_ELU':None}\n",
    "    else:\n",
    "        models = {\n",
    "            'DeepConvNet_ReLU': DeepConvNet(nn.ReLU()).to(device),\n",
    "            'DeepConvNet_LeakyReLU': DeepConvNet(nn.LeakyReLU()).to(device),\n",
    "            'DeepConvNet_ELU': DeepConvNet(nn.ELU()).to(device)\n",
    "        }\n",
    "        best_model_wts = {'DeepConvNet_ReLU':None,'DeepConvNet_LeakyReLU':None,'DeepConvNet_ELU':None}\n",
    "    \n",
    "    dfAcc = pd.DataFrame()\n",
    "    dfAcc['epoch'] = range(1, epochs+1)\n",
    "    dfloss = pd.DataFrame()\n",
    "    dfloss['epoch'] = range(1, epochs+1)\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        best_acc = 0.0\n",
    "        train_acc, test_acc, loss_epoch = [], [], []\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0.0\n",
    "            correct = 0.0\n",
    "            optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "            Loss_func = nn.CrossEntropyLoss()\n",
    "            model.train()\n",
    "#             print('epoch: ' + str(epoch + 1) + ' / ' + str(epochs))\n",
    "            \n",
    "            \"\"\" training state\"\"\"\n",
    "            for i, (data, label) in enumerate(train_dataloader):\n",
    "                data = data.to(device, dtype = torch.float)\n",
    "                label = label.to(device, dtype = torch.long)   # torch.LongTensor ==> 64位元\n",
    "                optimizer.zero_grad()   # gradient清空\n",
    "                \n",
    "                predicts = model(data)\n",
    "                loss = Loss_func(predicts, label)\n",
    "                total_loss += loss.item()\n",
    "                correct += predicts.max(dim=1)[1].eq(label).sum().item()\n",
    "                \n",
    "                \n",
    "                loss.backward()      # calculate gradient\n",
    "                optimizer.step()     # update loss\n",
    "\n",
    "            total_loss /= len(train_dataloader.dataset)\n",
    "            correct = 100.0 * correct / len(train_dataloader.dataset)\n",
    "            train_acc.append(correct)\n",
    "            loss_epoch.append(total_loss)\n",
    "            \n",
    "            \"\"\" testing state\"\"\"\n",
    "            model.eval()\n",
    "            tcorrect = 0.0\n",
    "            \n",
    "            for i, (data, label) in enumerate(test_dataloader):\n",
    "                with torch.no_grad():  # don't need gradient\n",
    "                    data = data.to(device, dtype = torch.float)\n",
    "                    label = label.to(device, dtype = torch.long)\n",
    "                    predicts = model(data)  \n",
    "                    tcorrect += predicts.max(dim=1)[1].eq(label).sum().item()  \n",
    "                    \n",
    "            tcorrect = 100.0 * tcorrect / len(test_dataloader.dataset)\n",
    "            test_acc.append(tcorrect)\n",
    "            \n",
    "            \"\"\" output train and test results \"\"\"\n",
    "            if epoch%10 == 0:\n",
    "                print('Training epoch: %d / loss: %.3f | acc: %.3f' %(epoch, total_loss, correct))\n",
    "                print('Test acc: %.3f' % tcorrect)\n",
    "            \n",
    "            \"\"\" update best model and accuracy \"\"\"\n",
    "            if tcorrect > best_acc:\n",
    "                best_model_wts[name] = copy.deepcopy(model.state_dict())\n",
    "                best_acc = tcorrect\n",
    "        \n",
    "        \"\"\" save return parameter \"\"\"\n",
    "        dfAcc[name+'_train'] = train_acc\n",
    "        dfAcc[name+'_test'] = test_acc\n",
    "        dfloss[name+'_loss'] = loss_epoch\n",
    "\n",
    "    return dfAcc, dfloss, best_model_wts \n",
    "\n",
    "# Batch size= 64 Learning rate = 1e-2 Epochs = 300\n",
    "# Optimizer: AdamLoss function: torch.nn.CrossEntropyLoss()\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # print(device)\n",
    "    batch_size = 64\n",
    "    lr = 0.001\n",
    "    epochs = 300\n",
    "    \n",
    "    \"\"\" load dataset \"\"\"\n",
    "    X_train, y_train, X_test, y_test = read_bci_data()\n",
    "    dataset = TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train))\n",
    "    train_dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = True)\n",
    "    \n",
    "    dataset = TensorDataset(torch.Tensor(X_test),torch.Tensor(y_test))\n",
    "    test_dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "    \"\"\" show dataset \"\"\"\n",
    "#     randi=int(np.random.randint(0,X_train.shape[0],1))\n",
    "#     print(f'sample_id:{randi}')\n",
    "#     plt.figure(figsize=(10,2))\n",
    "#     plt.plot(X_train[randi,0,0])\n",
    "#     plt.figure(figsize=(10,2))\n",
    "#     plt.plot(X_train[randi,0,1])\n",
    "    \n",
    "    \"\"\" model create 1 \"\"\"\n",
    "    EEG_acc, EEG_train_loss, best_model_wts = train(train_dataloader, test_dataloader, 'EEGNet')\n",
    "\n",
    "    for name, model_wts in best_model_wts.items():\n",
    "        torch.save(model_wts, './'+ name +'.pt')\n",
    "    \n",
    "    \"\"\" show results \"\"\"\n",
    "    plt.figure(figsize = (10,6))\n",
    "    for name in EEG_acc.columns[1:]:\n",
    "        plt.plot('epoch', name, data = EEG_acc)\n",
    "    plt.title('Activation function comparison (EEGNet)')\n",
    "    plt.ylabel('Accuracy (%)'), plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.savefig('eeg result.png')\n",
    "    \n",
    "    plt.figure(figsize = (10,6))\n",
    "    for name in EEG_train_loss.columns[1:]:\n",
    "        plt.plot('epoch',name, data = EEG_train_loss)\n",
    "    plt.title('Activation function comparison (EEGNet)')\n",
    "    plt.ylabel('loss'), plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.savefig('EEG_train_loss.png')\n",
    "    \n",
    "    print()\n",
    "    for column in EEG_acc.columns[1:]:\n",
    "        print(f'{column} best acc: {EEG_acc[column].max()}')\n",
    "    \n",
    "    \"\"\" model create 2 \"\"\"\n",
    "    print(\"\\n Doing DeepConvNet model \\n\")\n",
    "    DEEP_acc, DEEP_train_loss, DEEP_best_model_wts = train(train_dataloader, test_dataloader, 'DeepConvNet')\n",
    "    \n",
    "    for name, model_wts in DEEP_best_model_wts.items():\n",
    "        torch.save(model_wts, './'+ name +'.pt')\n",
    "\n",
    "    plt.figure(figsize = (10,6))\n",
    "    for name in DEEP_acc.columns[1:]:\n",
    "        plt.plot('epoch', name, data = DEEP_acc)\n",
    "    plt.title('Activation function comparison (DeepConvNet)')\n",
    "    plt.ylabel('Accuracy (%)'), plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.savefig('DEEP result.png')\n",
    "    \n",
    "    plt.figure(figsize = (10,6))\n",
    "    for name in DEEP_train_loss.columns[1:]:\n",
    "        plt.plot('epoch',name, data = DEEP_train_loss)\n",
    "    plt.title('Activation function comparison (DeepConvNet)')\n",
    "    plt.ylabel('loss'), plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.savefig('DEEP_train_loss.png')\n",
    "    \n",
    "    print()\n",
    "    for column in DEEP_acc.columns[1:]:\n",
    "        print(f'{column} best acc: {DEEP_acc[column].max()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ae359b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa0c872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
